<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="style.css">
<script src="script.js"></script>
<title>VCOMPRESSPD - Store Sparse Packed Double Precision Floating-Point Values Into Dense Memory </title></head>
<body>
<div id="head">
<a href="index.html">x86doc</a> › VCOMPRESSPD - Store Sparse Packed Double Precision Floating-Point Values Into Dense Memory </div>
<div id="body">
<h1>VCOMPRESSPD—Store Sparse Packed Double Precision Floating-Point Values Into Dense Memory</h1>
<table>
<tr>
<th>Opcode/Instruction</th>
<th>Op /En</th>
<th>64/32 bit Mode Support</th>
<th>CPUID Feature Flag</th>
<th>Description</th></tr>
<tr>
<td>EVEX.128.66.0F38.W1 8A /r VCOMPRESSPD xmm1/m128 {k1}{z}, xmm2</td>
<td>A</td>
<td>V/V</td>
<td>AVX512VL AVX512F</td>
<td>Compress packed double precision floating-point values from xmm2 to xmm1/m128 using writemask k1.</td></tr>
<tr>
<td>EVEX.256.66.0F38.W1 8A /r VCOMPRESSPD ymm1/m256 {k1}{z}, ymm2</td>
<td>A</td>
<td>V/V</td>
<td>AVX512VL AVX512F</td>
<td>Compress packed double precision floating-point values from ymm2 to ymm1/m256 using writemask k1.</td></tr>
<tr>
<td>EVEX.512.66.0F38.W1 8A /r VCOMPRESSPD zmm1/m512 {k1}{z}, zmm2</td>
<td>A</td>
<td>V/V</td>
<td>AVX512F</td>
<td>Compress packed double precision floating-point values from zmm2 using control mask k1 to zmm1/m512.</td></tr></table>
<h3>Instruction Operand Encoding</h3>
<table>
<tr>
<th>Op/En</th>
<th>Tuple Type</th>
<th>Operand 1</th>
<th>Operand 2</th>
<th>Operand 3</th>
<th>Operand 4</th></tr>
<tr>
<td>A</td>
<td>Tuple1 Scalar</td>
<td>ModRM:r/m (w)</td>
<td>ModRM:reg (r)</td>
<td>N/A</td>
<td>N/A</td></tr></table>
<p><strong>Description</strong></p>
<p>Compress (store) up to 8 double precision floating-point values from the source operand (the second operand) as a contiguous vector to the destination operand (the first operand) The source operand is a ZMM/YMM/XMM register, the destination operand can be a ZMM/YMM/XMM register or a 512/256/128-bit memory location.</p>
<p>The opmask register k1 selects the active elements (partial vector or possibly non-contiguous if less than 8 active elements) from the source operand to compress into a contiguous vector. The contiguous vector is written to the destination starting from the low element of the destination operand.</p>
<p>Memory destination version: Only the contiguous vector is written to the destination memory location. EVEX.z must be zero.</p>
<p>Register destination version: If the vector length of the contiguous vector is less than that of the input vector in the source operand, the upper bits of the destination register are unmodified if EVEX.z is not set, otherwise the upper bits are zeroed.</p>
<p>EVEX.vvvv is reserved and must be 1111b otherwise instructions will #UD.</p>
<p>Note that the compressed displacement assumes a pre-scaling (N) corresponding to the size of one single element instead of the size of the full vector.</p>
<p><strong>Operation</strong></p>
<p><strong>VCOMPRESSPD (EVEX Encoded Versions) Store Form</strong></p>
<p>(KL, VL) = (2, 128), (4, 256), (8, 512)</p>
<p>SIZE := 64</p>
<p>k := 0</p>
<p>FOR j := 0 TO KL-1</p>
<p>i := j * 64</p>
<p>IF k1[j] OR *no writemask*</p>
<p>THEN</p>
<p>DEST[k+SIZE-1:k] := SRC[i+63:i]</p>
<p>k := k + SIZE</p>
<p>FI;</p>
<p>ENDFOR</p>
<p><strong>VCOMPRESSPD (EVEX Encoded Versions) Reg-Reg Form</strong></p>
<p>(KL, VL) = (2, 128), (4, 256), (8, 512)</p>
<p>SIZE := 64</p>
<p>k := 0</p>
<p>FOR j := 0 TO KL-1</p>
<p>i := j * 64</p>
<p>IF k1[j] OR *no writemask*</p>
<p>THEN</p>
<p>DEST[k+SIZE-1:k] := SRC[i+63:i]</p>
<p>k := k + SIZE</p>
<p>FI;</p>
<p>ENDFOR</p>
<p>IF *merging-masking*</p>
<p>THEN *DEST[VL-1:k] remains unchanged*</p>
<p>ELSE DEST[VL-1:k] := 0</p>
<p>FI</p>
<p>DEST[MAXVL-1:VL] := 0</p>
<p><strong>Intel C/C++ Compiler Intrinsic Equivalent</strong></p>
<p>VCOMPRESSPD __m512d _mm512_mask_compress_pd( __m512d s, __mmask8 k, __m512d a);</p>
<p>VCOMPRESSPD __m512d _mm512_maskz_compress_pd( __mmask8 k, __m512d a);</p>
<p>VCOMPRESSPD void _mm512_mask_compressstoreu_pd( void * d, __mmask8 k, __m512d a);</p>
<p>VCOMPRESSPD __m256d _mm256_mask_compress_pd( __m256d s, __mmask8 k, __m256d a);</p>
<p>VCOMPRESSPD __m256d _mm256_maskz_compress_pd( __mmask8 k, __m256d a);</p>
<p>VCOMPRESSPD void _mm256_mask_compressstoreu_pd( void * d, __mmask8 k, __m256d a);</p>
<p>VCOMPRESSPD __m128d _mm_mask_compress_pd( __m128d s, __mmask8 k, __m128d a);</p>
<p>VCOMPRESSPD __m128d _mm_maskz_compress_pd( __mmask8 k, __m128d a);</p>
<p>VCOMPRESSPD void _mm_mask_compressstoreu_pd( void * d, __mmask8 k, __m128d a);</p>
<p><strong>SIMD Floating-Point Exceptions</strong></p>
<p>None.</p>
<p><strong>Other Exceptions</strong></p>
<p>EVEX-encoded instructions, see Exceptions Type E4.nb in Table 2-49, “Type E4 Class Exception Conditions.”</p>
<p>Additionally:</p>
<table>
<tr>
<td>#UD</td>
<td>If EVEX.vvvv != 1111B.</td></tr></table></div></body></html>