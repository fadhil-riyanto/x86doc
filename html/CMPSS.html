<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="style.css">
<script src="script.js"></script>
<title>CMPSS - Compare Scalar Single Precision Floating-Point Value </title></head>
<body>
<div id="head">
<a href="index.html">x86doc</a> › CMPSS - Compare Scalar Single Precision Floating-Point Value </div>
<div id="body">
<h1>CMPSS—Compare Scalar Single Precision Floating-Point Value</h1>
<table>
<tr>
<th>Opcode/Instruction</th>
<th>Op /En</th>
<th>64/32 bit Mode Support</th>
<th>CPUID Feature Flag</th>
<th>Description</th></tr>
<tr>
<td>F3 0F C2 /r ib CMPSS xmm1, xmm2/m32, imm8</td>
<td>A</td>
<td>V/V</td>
<td>SSE</td>
<td>Compare low single precision floating-point value in xmm2/m32 and xmm1 using bits 2:0 of imm8 as comparison predicate.</td></tr>
<tr>
<td>VEX.LIG.F3.0F.WIG C2 /r ib VCMPSS xmm1, xmm2, xmm3/m32, imm8</td>
<td>B</td>
<td>V/V</td>
<td>AVX</td>
<td>Compare low single precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate.</td></tr>
<tr>
<td>EVEX.LLIG.F3.0F.W0 C2 /r ib VCMPSS k1 {k2}, xmm2, xmm3/m32{sae}, imm8</td>
<td>C</td>
<td>V/V</td>
<td>AVX512F</td>
<td>Compare low single precision floating-point value in xmm3/m32 and xmm2 using bits 4:0 of imm8 as comparison predicate with writemask k2 and leave the result in mask register k1.</td></tr></table>
<h3>Instruction Operand Encoding</h3>
<table>
<tr>
<th>Op/En</th>
<th>Tuple Type</th>
<th>Operand 1</th>
<th>Operand 2</th>
<th>Operand 3</th>
<th>Operand 4</th></tr>
<tr>
<td>A</td>
<td>N/A</td>
<td>ModRM:reg (r, w)</td>
<td>ModRM:r/m (r)</td>
<td>imm8</td>
<td>N/A</td></tr>
<tr>
<td>B</td>
<td>N/A</td>
<td>ModRM:reg (w)</td>
<td>VEX.vvvv (r)</td>
<td>ModRM:r/m (r)</td>
<td>imm8</td></tr>
<tr>
<td>C</td>
<td>Tuple1 Scalar</td>
<td>ModRM:reg (w)</td>
<td>EVEX.vvvv (r)</td>
<td>ModRM:r/m (r)</td>
<td>imm8</td></tr></table>
<h2>Description</h2>
<p>Compares the low single precision floating-point values in the second source operand and the first source operand and returns the result of the comparison to the destination operand. The comparison predicate operand (imme-diate operand) specifies the type of comparison performed.</p>
<p>128-bit Legacy SSE version: The first source and destination operand (first operand) is an XMM register. The second source operand (second operand) can be an XMM register or 32-bit memory location. Bits (MAXVL-1:32) of the corresponding YMM destination register remain unchanged. The comparison result is a doubleword mask of all 1s (comparison true) or all 0s (comparison false).</p>
<p>VEX.128 encoded version: The first source operand (second operand) is an XMM register. The second source operand (third operand) can be an XMM register or a 32-bit memory location. The result is stored in the low 32 bits of the destination operand; bits 127:32 of the destination operand are copied from the first source operand. Bits (MAXVL-1:128) of the destination ZMM register are zeroed. The comparison result is a doubleword mask of all 1s (comparison true) or all 0s (comparison false).</p>
<p>EVEX encoded version: The first source operand (second operand) is an XMM register. The second source operand can be a XMM register or a 32-bit memory location. The destination operand (first operand) is an opmask register. The comparison result is a single mask bit of 1 (comparison true) or 0 (comparison false), written to the destination starting from the LSB according to the writemask k2. Bits (MAX_KL-1:128) of the destination register are cleared.</p>
<p>The comparison predicate operand is an 8-bit immediate:</p>
<p>The unordered relationship is true when at least one of the two source operands being compared is a NaN; the ordered relationship is true when neither source operand is a NaN.</p>
<p>A subsequent computational instruction that uses the mask result in the destination operand as an input operand will not generate an exception, because a mask of all 0s corresponds to a floating-point value of +0.0 and a mask of all 1s corresponds to a QNaN.</p>
<p>Note that processors with “CPUID.1H:ECX.AVX =0” do not implement the “greater-than”, “greater-than-or-equal”, “not-greater than”, and “not-greater-than-or-equal relations” predicates. These comparisons can be made either by using the inverse relationship (that is, use the “not-less-than-or-equal” to make a “greater-than” comparison) or by using software emulation. When using software emulation, the program must swap the operands (copying registers when necessary to protect the data that will now be in the destination), and then perform the compare using a different predicate. The predicate to be used for these emulations is listed in the first 8 rows of Table 3-7 (<em>Intel 64 and IA-32 Architectures Software Developer’s Manual Volume 2A</em>) under the heading Emulation.</p>
<p>Compilers and assemblers may implement the following two-operand pseudo-ops in addition to the three-operand CMPSS instruction, for processors with “CPUID.1H:ECX.AVX =0”. See Table 3-8. The compiler should treat reserved imm8 values as illegal syntax.</p>
<h3>Table 3-8. Pseudo-Op and CMPSS Implementation</h3>
<p>:</p>
<table>
<tr>
<th>Pseudo-Op</th>
<th>CMPSS Implementation</th></tr>
<tr>
<td>CMPEQSS xmm1, xmm2</td>
<td>CMPSS xmm1, xmm2, 0</td></tr>
<tr>
<td>CMPLTSS xmm1, xmm2</td>
<td>CMPSS xmm1, xmm2, 1</td></tr>
<tr>
<td>CMPLESS xmm1, xmm2</td>
<td>CMPSS xmm1, xmm2, 2</td></tr>
<tr>
<td>CMPUNORDSS xmm1, xmm2</td>
<td>CMPSS xmm1, xmm2, 3</td></tr>
<tr>
<td>CMPNEQSS xmm1, xmm2</td>
<td>CMPSS xmm1, xmm2, 4</td></tr>
<tr>
<td>CMPNLTSS xmm1, xmm2</td>
<td>CMPSS xmm1, xmm2, 5</td></tr>
<tr>
<td>CMPNLESS xmm1, xmm2</td>
<td>CMPSS xmm1, xmm2, 6</td></tr>
<tr>
<td>CMPORDSS xmm1, xmm2</td>
<td>CMPSS xmm1, xmm2, 7</td></tr></table>
<p>The greater-than relations that the processor does not implement require more than one instruction to emulate in software and therefore should not be implemented as pseudo-ops. (For these, the programmer should reverse the operands of the corresponding less than relations and use move instructions to ensure that the mask is moved to the correct destination register and that the source operand is left intact.)</p>
<p>Processors with “CPUID.1H:ECX.AVX =1” implement the full complement of 32 predicates shown in Table 3-7, soft-ware emulation is no longer needed. Compilers and assemblers may implement the following three-operand pseudo-ops in addition to the four-operand VCMPSS instruction. See Table 3-9, where the notations of reg1 reg2, and reg3 represent either XMM registers or YMM registers. The compiler should treat reserved imm8 values as illegal syntax. Alternately, intrinsics can map the pseudo-ops to pre-defined constants to support a simpler intrinsic interface. Compilers and assemblers may implement three-operand pseudo-ops for EVEX encoded VCMPSS instructions in a similar fashion by extending the syntax listed in Table 3-9.</p>
<h3>Table 3-9. Pseudo-Op and VCMPSS Implementation</h3>
<p>:</p>
<table>
<tr>
<th>Pseudo-Op</th>
<th>CMPSS Implementation</th></tr>
<tr>
<td>VCMPEQSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 0</td></tr>
<tr>
<td>VCMPLTSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 1</td></tr>
<tr>
<td>VCMPLESS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 2</td></tr>
<tr>
<td>VCMPUNORDSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 3</td></tr>
<tr>
<td>VCMPNEQSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 4</td></tr>
<tr>
<td>VCMPNLTSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 5</td></tr>
<tr>
<td>VCMPNLESS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 6</td></tr>
<tr>
<td>VCMPORDSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 7</td></tr>
<tr>
<td>VCMPEQ_UQSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 8</td></tr>
<tr>
<td>VCMPNGESS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 9</td></tr>
<tr>
<td>VCMPNGTSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 0AH</td></tr>
<tr>
<td>VCMPFALSESS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 0BH</td></tr></table>
<h3>Table 3-9. Pseudo-Op and VCMPSS Implementation</h3>
<table>
<tr>
<th>Pseudo-Op</th>
<th>CMPSS Implementation</th></tr>
<tr>
<td>VCMPNEQ_OQSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 0CH</td></tr>
<tr>
<td>VCMPGESS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 0DH</td></tr>
<tr>
<td>VCMPGTSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 0EH</td></tr>
<tr>
<td>VCMPTRUESS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 0FH</td></tr>
<tr>
<td>VCMPEQ_OSSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 10H</td></tr>
<tr>
<td>VCMPLT_OQSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 11H</td></tr>
<tr>
<td>VCMPLE_OQSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 12H</td></tr>
<tr>
<td>VCMPUNORD_SSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 13H</td></tr>
<tr>
<td>VCMPNEQ_USSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 14H</td></tr>
<tr>
<td>VCMPNLT_UQSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 15H</td></tr>
<tr>
<td>VCMPNLE_UQSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 16H</td></tr>
<tr>
<td>VCMPORD_SSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 17H</td></tr>
<tr>
<td>VCMPEQ_USSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 18H</td></tr>
<tr>
<td>VCMPNGE_UQSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 19H</td></tr>
<tr>
<td>VCMPNGT_UQSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 1AH</td></tr>
<tr>
<td>VCMPFALSE_OSSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 1BH</td></tr>
<tr>
<td>VCMPNEQ_OSSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 1CH</td></tr>
<tr>
<td>VCMPGE_OQSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 1DH</td></tr>
<tr>
<td>VCMPGT_OQSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 1EH</td></tr>
<tr>
<td>VCMPTRUE_USSS reg1, reg2, reg3</td>
<td>VCMPSS reg1, reg2, reg3, 1FH</td></tr></table>
<p>Software should ensure VCMPSS is encoded with VEX.L=0. Encoding VCMPSS with VEX.L=1 may encounter unpre-dictable behavior across different processor generations.</p>
<h2>Operation</h2>
<pre>CASE (COMPARISON PREDICATE) OF
    0: OP3 := EQ_OQ; OP5 := EQ_OQ;
    1: OP3 := LT_OS; OP5 := LT_OS;
    2: OP3 := LE_OS; OP5 := LE_OS;
    3: OP3 := UNORD_Q; OP5 := UNORD_Q;
    4: OP3 := NEQ_UQ; OP5 := NEQ_UQ;
    5: OP3 := NLT_US; OP5 := NLT_US;
    6: OP3 := NLE_US; OP5 := NLE_US;
    7: OP3 := ORD_Q; OP5 := ORD_Q;
    8: OP5 := EQ_UQ;
    9: OP5 := NGE_US;
    10: OP5 := NGT_US;
    11: OP5 := FALSE_OQ;
    12: OP5 := NEQ_OQ;
    13: OP5 := GE_OS;
    14: OP5 := GT_OS;
    15: OP5 := TRUE_UQ;
    16: OP5 := EQ_OS;
    17: OP5 := LT_OQ;
    18: OP5 := LE_OQ;
    19: OP5 := UNORD_S;
    20: OP5 := NEQ_US;
    21: OP5 := NLT_UQ;
    22: OP5 := NLE_UQ;
    23: OP5 := ORD_S;
    24: OP5 := EQ_US;
    25: OP5 := NGE_UQ;
    26: OP5 := NGT_UQ;
    27: OP5 := FALSE_OS;
    28: OP5 := NEQ_OS;
    29: OP5 := GE_OQ;
    30: OP5 := GT_OQ;
    31: OP5 := TRUE_US;
    DEFAULT: Reserved
ESAC;</pre>
<p><strong>VCMPSS (EVEX Encoded Version)</strong></p>
<pre>CMP0 := SRC1[31:0] OP5 SRC2[31:0];
IF k2[0] or *no writemask*
    THEN
              IF CMP0 = TRUE
                    THEN DEST[0] := 1;
                    ELSE DEST[0] := 0; FI;
    ELSE
              DEST[0] := 0
                                              ; zeroing-masking only
FI;
DEST[MAX_KL-1:1] := 0</pre>
<p><strong>CMPSS (128-bit Legacy SSE Version)</strong></p>
<pre>CMP0 := DEST[31:0] OP3 SRC[31:0];
IF CMP0 = TRUE
THEN DEST[31:0] := FFFFFFFFH;
ELSE DEST[31:0] := 00000000H; FI;
DEST[MAXVL-1:32] (Unmodified)</pre>
<p><strong>VCMPSS (VEX.128 Encoded Version)</strong></p>
<pre>CMP0 := SRC1[31:0] OP5 SRC2[31:0];
IF CMP0 = TRUE
THEN DEST[31:0] := FFFFFFFFH;
ELSE DEST[31:0] := 00000000H; FI;
DEST[127:32] := SRC1[127:32]
DEST[MAXVL-1:128] := 0</pre>
<h2>Intel C/C++ Compiler Intrinsic Equivalent</h2>
<p>VCMPSS __mmask8 _mm_cmp_ss_mask( __m128 a, __m128 b, int imm);</p>
<p>VCMPSS __mmask8 _mm_cmp_round_ss_mask( __m128 a, __m128 b, int imm, int sae);</p>
<p>VCMPSS __mmask8 _mm_mask_cmp_ss_mask( __mmask8 k1, __m128 a, __m128 b, int imm);</p>
<p>VCMPSS __mmask8 _mm_mask_cmp_round_ss_mask( __mmask8 k1, __m128 a, __m128 b, int imm, int sae);</p>
<p>(V)CMPSS __m128 _mm_cmp_ss(__m128 a, __m128 b, const int imm)</p>
<h2>SIMD Floating-Point Exceptions</h2>
<p>Invalid if SNaN operand, Invalid if QNaN and predicate as listed in Table 3-1, Denormal.</p>
<h2>Other Exceptions</h2>
<table class="exception-table">
<tr>
<td>VEX-encoded instructions, see Table 2-20, “Type 3 Class Exception Conditions.”</td></tr>
<tr>
<td>EVEX-encoded instructions, see Table 2-47, “Type E3 Class Exception Conditions.”</td></tr></table></div></body></html>