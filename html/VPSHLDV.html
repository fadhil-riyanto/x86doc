<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="style.css">
<script src="script.js"></script>
<title>VPSHLDV - Concatenate and Variable Shift Packed Data Left Logical </title></head>
<body>
<div id="head">
<a href="index.html">x86doc</a> › VPSHLDV - Concatenate and Variable Shift Packed Data Left Logical </div>
<div id="body">
<h1>VPSHLDV—Concatenate and Variable Shift Packed Data Left Logical</h1>
<table>
<tr>
<th>Opcode/Instruction</th>
<th>Op/En</th>
<th>64/32 bit Mode Support</th>
<th>CPUID Feature Flag</th>
<th>Description</th></tr>
<tr>
<td>EVEX.128.66.0F38.W1 70 /r VPSHLDVW xmm1{k1}{z}, xmm2, xmm3/m128</td>
<td>A</td>
<td>V/V</td>
<td>AVX512_VBMI2 AVX512VL</td>
<td>Concatenate xmm1 and xmm2, extract result shifted to the left by value in xmm3/m128 into xmm1.</td></tr>
<tr>
<td>EVEX.256.66.0F38.W1 70 /r VPSHLDVW ymm1{k1}{z}, ymm2, ymm3/m256</td>
<td>A</td>
<td>V/V</td>
<td>AVX512_VBMI2 AVX512VL</td>
<td>Concatenate ymm1 and ymm2, extract result shifted to the left by value in xmm3/m256 into ymm1.</td></tr>
<tr>
<td>EVEX.512.66.0F38.W1 70 /r VPSHLDVW zmm1{k1}{z}, zmm2, zmm3/m512</td>
<td>A</td>
<td>V/V</td>
<td>AVX512_VBMI2</td>
<td>Concatenate zmm1 and zmm2, extract result shifted to the left by value in zmm3/m512 into zmm1.</td></tr>
<tr>
<td>EVEX.128.66.0F38.W0 71 /r VPSHLDVD xmm1{k1}{z}, xmm2, xmm3/m128/m32bcst</td>
<td>B</td>
<td>V/V</td>
<td>AVX512_VBMI2 AVX512VL</td>
<td>Concatenate xmm1 and xmm2, extract result shifted to the left by value in xmm3/m128 into xmm1.</td></tr>
<tr>
<td>EVEX.256.66.0F38.W0 71 /r VPSHLDVD ymm1{k1}{z}, ymm2, ymm3/m256/m32bcst</td>
<td>B</td>
<td>V/V</td>
<td>AVX512_VBMI2 AVX512VL</td>
<td>Concatenate ymm1 and ymm2, extract result shifted to the left by value in xmm3/m256 into ymm1.</td></tr>
<tr>
<td>EVEX.512.66.0F38.W0 71 /r VPSHLDVD zmm1{k1}{z}, zmm2, zmm3/m512/m32bcst</td>
<td>B</td>
<td>V/V</td>
<td>AVX512_VBMI2</td>
<td>Concatenate zmm1 and zmm2, extract result shifted to the left by value in zmm3/m512 into zmm1.</td></tr>
<tr>
<td>EVEX.128.66.0F38.W1 71 /r VPSHLDVQ xmm1{k1}{z}, xmm2, xmm3/m128/m64bcst</td>
<td>B</td>
<td>V/V</td>
<td>AVX512_VBMI2 AVX512VL</td>
<td>Concatenate xmm1 and xmm2, extract result shifted to the left by value in xmm3/m128 into xmm1.</td></tr>
<tr>
<td>EVEX.256.66.0F38.W1 71 /r VPSHLDVQ ymm1{k1}{z}, ymm2, ymm3/m256/m64bcst</td>
<td>B</td>
<td>V/V</td>
<td>AVX512_VBMI2 AVX512VL</td>
<td>Concatenate ymm1 and ymm2, extract result shifted to the left by value in xmm3/m256 into ymm1.</td></tr>
<tr>
<td>EVEX.512.66.0F38.W1 71 /r VPSHLDVQ zmm1{k1}{z}, zmm2, zmm3/m512/m64bcst</td>
<td>B</td>
<td>V/V</td>
<td>AVX512_VBMI2</td>
<td>Concatenate zmm1 and zmm2, extract result shifted to the left by value in zmm3/m512 into zmm1.</td></tr></table>
<h3>Instruction Operand Encoding</h3>
<table>
<tr>
<th>Op/En</th>
<th>Tuple</th>
<th>Operand 1</th>
<th>Operand 2</th>
<th>Operand 3</th>
<th>Operand 4</th></tr>
<tr>
<td>A</td>
<td>Full Mem</td>
<td>ModRM:reg (r, w)</td>
<td>EVEX.vvvv (r)</td>
<td>ModRM:r/m (r)</td>
<td>N/A</td></tr>
<tr>
<td>B</td>
<td>Full</td>
<td>ModRM:reg (r, w)</td>
<td>EVEX.vvvv (r)</td>
<td>ModRM:r/m (r)</td>
<td>N/A</td></tr></table>
<p><strong>Description</strong></p>
<p>Concatenate packed data, extract result shifted to the left by variable value.</p>
<p>This instruction supports memory fault suppression.</p>
<p><strong>Operation</strong></p>
<p>FUNCTION concat(a,b):</p>
<p>IF words:</p>
<p>d.word[1] := a</p>
<p>d.word[0] := b</p>
<p>return d</p>
<p>ELSE IF dwords:</p>
<p>q.dword[1] := a</p>
<p>q.dword[0] := b</p>
<p>return q</p>
<p>ELSE IF qwords:</p>
<p>o.qword[1] := a</p>
<p>o.qword[0] := b</p>
<p>return o</p>
<p><strong>VPSHLDVW DEST, SRC2, SRC3</strong></p>
<p>(KL, VL) = (8, 128), (16, 256), (32, 512)</p>
<p>FOR j := 0 TO KL-1:</p>
<p>IF MaskBit(j) OR *no writemask*:</p>
<p>tmp := concat(DEST.word[j], SRC2.word[j]) &lt;&lt; (SRC3.word[j] &amp; 15)</p>
<p>DEST.word[j] := tmp.word[1]</p>
<p>ELSE IF *zeroing*:</p>
<p>DEST.word[j] := 0</p>
<p>*ELSE DEST.word[j] remains unchanged*</p>
<p>DEST[MAX_VL-1:VL] := 0</p>
<p><strong>VPSHLDVD DEST, SRC2, SRC3</strong></p>
<p>(KL, VL) = (4, 128), (8, 256), (16, 512)</p>
<p>FOR j := 0 TO KL-1:</p>
<p>IF SRC3 is broadcast memop:</p>
<p>tsrc3 := SRC3.dword[0]</p>
<p>ELSE:</p>
<p>tsrc3 := SRC3.dword[j]</p>
<p>IF MaskBit(j) OR *no writemask*:</p>
<p>tmp := concat(DEST.dword[j], SRC2.dword[j]) &lt;&lt; (tsrc3 &amp; 31)</p>
<p>DEST.dword[j] := tmp.dword[1]</p>
<p>ELSE IF *zeroing*:</p>
<p>DEST.dword[j] := 0</p>
<p>*ELSE DEST.dword[j] remains unchanged*</p>
<p>DEST[MAX_VL-1:VL] := 0</p>
<p><strong>VPSHLDVQ DEST, SRC2, SRC3</strong></p>
<p>(KL, VL) = (2, 128), (4, 256), (8, 512)</p>
<p>FOR j := 0 TO KL-1:</p>
<p>IF SRC3 is broadcast memop:</p>
<p>tsrc3 := SRC3.qword[0]</p>
<p>ELSE:</p>
<p>tsrc3 := SRC3.qword[j]</p>
<p>IF MaskBit(j) OR *no writemask*:</p>
<p>tmp := concat(DEST.qword[j], SRC2.qword[j]) &lt;&lt; (tsrc3 &amp; 63)</p>
<p>DEST.qword[j] := tmp.qword[1]</p>
<p>ELSE IF *zeroing*:</p>
<p>DEST.qword[j] := 0</p>
<p>*ELSE DEST.qword[j] remains unchanged*</p>
<p>DEST[MAX_VL-1:VL] := 0</p>
<p><strong>Intel C/C++ Compiler Intrinsic Equivalent</strong></p>
<p>VPSHLDVW __m128i _mm_shldv_epi16(__m128i, __m128i, __m128i);</p>
<p>VPSHLDVW __m128i _mm_mask_shldv_epi16(__m128i, __mmask8, __m128i, __m128i);</p>
<p>VPSHLDVW __m128i _mm_maskz_shldv_epi16(__mmask8, __m128i, __m128i, __m128i);</p>
<p>VPSHLDVW __m256i _mm256_shldv_epi16(__m256i, __m256i, __m256i);</p>
<p>VPSHLDVW __m256i _mm256_mask_shldv_epi16(__m256i, __mmask16, __m256i, __m256i);</p>
<p>VPSHLDVW __m256i _mm256_maskz_shldv_epi16(__mmask16, __m256i, __m256i, __m256i);</p>
<p>VPSHLDVQ __m512i  _mm512_shldv_epi64(__m512i, __m512i, __m512i);</p>
<p>VPSHLDVQ __m512i  _mm512_mask_shldv_epi64(__m512i, __mmask8, __m512i, __m512i);</p>
<p>VPSHLDVQ __m512i  _mm512_maskz_shldv_epi64(__mmask8, __m512i, __m512i, __m512i);</p>
<p>VPSHLDVW __m128i  _mm_shldv_epi16(__m128i, __m128i, __m128i);</p>
<p>VPSHLDVW __m128i  _mm_mask_shldv_epi16(__m128i, __mmask8, __m128i, __m128i);</p>
<p>VPSHLDVW __m128i  _mm_maskz_shldv_epi16(__mmask8, __m128i, __m128i, __m128i);</p>
<p>VPSHLDVW __m256i  _mm256_shldv_epi16(__m256i, __m256i, __m256i);</p>
<p>VPSHLDVW __m256i  _mm256_mask_shldv_epi16(__m256i, __mmask16, __m256i, __m256i);</p>
<p>VPSHLDVW __m256i  _mm256_maskz_shldv_epi16(__mmask16, __m256i, __m256i, __m256i);</p>
<p>VPSHLDVW __m512i  _mm512_shldv_epi16(__m512i, __m512i, __m512i);</p>
<p>VPSHLDVW __m512i  _mm512_mask_shldv_epi16(__m512i, __mmask32, __m512i, __m512i);</p>
<p>VPSHLDVW __m512i  _mm512_maskz_shldv_epi16(__mmask32, __m512i, __m512i, __m512i);</p>
<p>VPSHLDVD __m128i  _mm_shldv_epi32(__m128i, __m128i, __m128i);</p>
<p>VPSHLDVD __m128i  _mm_mask_shldv_epi32(__m128i, __mmask8, __m128i, __m128i);</p>
<p>VPSHLDVD __m128i  _mm_maskz_shldv_epi32(__mmask8, __m128i, __m128i, __m128i);</p>
<p>VPSHLDVD __m256i  _mm256_shldv_epi32(__m256i, __m256i, __m256i);</p>
<p>VPSHLDVD __m256i  _mm256_mask_shldv_epi32(__m256i, __mmask8, __m256i, __m256i);</p>
<p>VPSHLDVD __m256i  _mm256_maskz_shldv_epi32(__mmask8, __m256i, __m256i, __m256i);</p>
<p>VPSHLDVD __m512i  _mm512_shldv_epi32(__m512i, __m512i, __m512i);</p>
<p>VPSHLDVD __m512i  _mm512_mask_shldv_epi32(__m512i, __mmask16, __m512i, __m512i);</p>
<p>VPSHLDVD __m512i  _mm512_maskz_shldv_epi32(__mmask16, __m512i, __m512i, __m512i);</p>
<p><strong>SIMD Floating-Point Exceptions</strong></p>
<p>None.</p>
<p><strong>Other Exceptions</strong></p>
<p>See Table 2-49, “Type E4 Class Exception Conditions.”</p></div></body></html>