<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="style.css">
<script src="script.js"></script>
<title>VPMADD52LUQ - Packed Multiply of Unsigned 52-Bit Integers and Add the Low 52-Bit Products to Qword Accumulators </title></head>
<body>
<div id="head">
<a href="index.html">x86doc</a> › VPMADD52LUQ - Packed Multiply of Unsigned 52-Bit Integers and Add the Low 52-Bit Products to Qword Accumulators </div>
<div id="body">
<h1>VPMADD52LUQ—Packed Multiply of Unsigned 52-Bit Integers and Add the Low 52-Bit Products to Qword Accumulators</h1>
<table>
<tr>
<td>
<p><strong>Opcode/</strong></p>
<p><strong>Instruction</strong></p></td>
<td>Op/En</td>
<td>
<p><strong>32/64</strong></p>
<p><strong>bit Mode</strong></p>
<p><strong>Support</strong></p></td>
<td>CPUID</td>
<td>Description</td></tr>
<tr>
<td>EVEX.128.66.0F38.W1 B4 /r VPMADD52LUQ xmm1 {k1}{z}, xmm2,xmm3/m128/m64bcst</td>
<td>A</td>
<td>V/V</td>
<td>AVX512_IFMA AVX512VL</td>
<td>Multiply unsigned 52-bit integers in xmm2 and xmm3/m128 and add the low 52 bits of the 104-bit product to the qword unsigned integers in xmm1 using writemask k1.</td></tr>
<tr>
<td>EVEX.256.66.0F38.W1 B4 /r VPMADD52LUQ ymm1 {k1}{z}, ymm2, ymm3/m256/m64bcst</td>
<td>A</td>
<td>V/V</td>
<td>AVX512_IFMA AVX512VL</td>
<td>Multiply unsigned 52-bit integers in ymm2 and ymm3/m256 and add the low 52 bits of the 104-bit product to the qword unsigned integers in ymm1 using writemask k1.</td></tr>
<tr>
<td>EVEX.512.66.0F38.W1 B4 /r VPMADD52LUQ zmm1 {k1}{z}, zmm2,zmm3/m512/m64bcst</td>
<td>A</td>
<td>V/V</td>
<td>AVX512_IFMA</td>
<td>Multiply unsigned 52-bit integers in zmm2 and zmm3/m512 and add the low 52 bits of the 104-bit product to the qword unsigned integers in zmm1 using writemask k1.</td></tr></table>
<h3>Instruction Operand Encoding</h3>
<table>
<tr>
<th>Op/En</th>
<th>Tuple Type</th>
<th>Operand 1</th>
<th>Operand 2</th>
<th>Operand 3</th>
<th>Operand 4</th></tr>
<tr>
<td>A</td>
<td>Full</td>
<td>ModRM:reg (r, w)</td>
<td>EVEX.vvvv (r)</td>
<td>ModRM:r/m(r)</td>
<td>N/A</td></tr></table>
<p><strong>Description</strong></p>
<p>Multiplies packed unsigned 52-bit integers in each qword element of the first source operand (the second oper-and) with the packed unsigned 52-bit integers in the corresponding elements of the second source operand (the third operand) to form packed 104-bit intermediate results. The low 52-bit, unsigned integer of each 104-bit product is added to the corresponding qword unsigned integer of the destination operand (the first operand) under the writemask k1.</p>
<p>The first source operand is a ZMM/YMM/XMM register. The second source operand can be a ZMM/YMM/XMM reg-ister, a 512/256/128-bit memory location or a 512/256/128-bit vector broadcasted from a 64-bit memory loca-tion. The destination operand is a ZMM/YMM/XMM register conditionally updated with writemask k1 at 64-bit granularity.</p>
<p><strong>Operation</strong></p>
<p><strong>VPMADD52LUQ (EVEX encoded)</strong></p>
<p>(KL, VL) = (2, 128), (4, 256), (8, 512)</p>
<p>FOR j := 0 TO KL-1</p>
<p>i := j * 64;</p>
<p>IF k1[j] OR *no writemask* THEN</p>
<p>IF src2 is Memory AND EVEX.b=1 THEN</p>
<p>tsrc2[63:0] := ZeroExtend64(src2[51:0]);</p>
<p>ELSE</p>
<p>tsrc2[63:0] := ZeroExtend64(src2[i+51:i];</p>
<p>FI;</p>
<p>Temp128[127:0] := ZeroExtend64(src1[i+51:i]) * tsrc2[63:0];</p>
<p>Temp2[63:0] := DEST[i+63:i] + ZeroExtend64(temp128[51:0]) ;</p>
<p>DEST[i+63:i] := Temp2[63:0];</p>
<p>ELSE</p>
<p>IF *zeroing-masking* THEN</p>
<p>DEST[i+63:i] := 0;</p>
<p>ELSE *merge-masking*</p>
<p>DEST[i+63:i] is unchanged;</p>
<p>FI;</p>
<p>FI;</p>
<p>ENDFOR</p>
<p>DEST[MAX_VL-1:VL] := 0;</p>
<p><strong>Intel C/C++ Compiler Intrinsic Equivalent</strong></p>
<p>VPMADD52LUQ __m512i _mm512_madd52lo_epu64( __m512i a, __m512i b, __m512i c);</p>
<p>VPMADD52LUQ __m512i _mm512_mask_madd52lo_epu64(__m512i s, __mmask8 k, __m512i a, __m512i b, __m512i c);</p>
<p>VPMADD52LUQ __m512i _mm512_maskz_madd52lo_epu64( __mmask8 k, __m512i a, __m512i b, __m512i c);</p>
<p>VPMADD52LUQ __m256i _mm256_madd52lo_epu64( __m256i a, __m256i b, __m256i c);</p>
<p>VPMADD52LUQ __m256i _mm256_mask_madd52lo_epu64(__m256i s, __mmask8 k, __m256i a, __m256i b, __m256i c);</p>
<p>VPMADD52LUQ __m256i _mm256_maskz_madd52lo_epu64( __mmask8 k, __m256i a, __m256i b, __m256i c);</p>
<p>VPMADD52LUQ __m128i _mm_madd52lo_epu64( __m128i a, __m128i b, __m128i c);</p>
<p>VPMADD52LUQ __m128i _mm_mask_madd52lo_epu64(__m128i s, __mmask8 k, __m128i a, __m128i b, __m128i c);</p>
<p>VPMADD52LUQ __m128i _mm_maskz_madd52lo_epu64( __mmask8 k, __m128i a, __m128i b, __m128i c);</p>
<p><strong>Flags Affected</strong></p>
<p>None.</p>
<p><strong>SIMD Floating-Point Exceptions</strong></p>
<p>None.</p>
<p><strong>Other Exceptions</strong></p>
<p>See Table 2-49, “Type E4 Class Exception Conditions.”</p></div></body></html>